{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58096d62-304a-4544-b0da-5b1628831bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from sam3.model_builder import build_sam3_image_model\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "import numpy as np\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ab80130-2c18-49fa-9883-e972718e156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_masks(image, masks):\n",
    "    image = image.convert(\"RGBA\")\n",
    "    masks = 255 * masks.cpu().numpy().astype(np.uint8)\n",
    "    \n",
    "    n_masks = masks.shape[0]\n",
    "    cmap = matplotlib.colormaps.get_cmap(\"rainbow\").resampled(n_masks)\n",
    "    colors = [\n",
    "        tuple(int(c * 255) for c in cmap(i)[:3])\n",
    "        for i in range(n_masks)\n",
    "    ]\n",
    "\n",
    "    for mask, color in zip(masks, colors):\n",
    "        mask = Image.fromarray(mask)\n",
    "        overlay = Image.new(\"RGBA\", image.size, color + (0,))\n",
    "        alpha = mask.point(lambda v: int(v * 0.5))\n",
    "        overlay.putalpha(alpha)\n",
    "        image = Image.alpha_composite(image, overlay)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5d1580-fd96-40dc-98b8-b4c774d611f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5bcc0ffa684ba189df068f9437e7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69568817-8271-40bf-ac4e-4fbc255f8610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25163b6c65cf46448d4a5e78b64e8589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sam3.pt:   0%|          | 0.00/3.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_sam3_image_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d21f5c3-c9c3-49c9-8b37-4b160f684a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Sam3Processor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "745b2cac-3a57-4a51-a5dd-8d5441a8ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "image = Image.open(\"../data/truck.jpg\")\n",
    "inference_state = processor.set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa96fd9d-f6ef-4875-a314-e23adb8ebb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the model with text\n",
    "output = processor.set_text_prompt(state=inference_state, prompt=\"truck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bef6320-05d7-498b-a739-1b2f4f5163f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the masks, bounding boxes, and scores\n",
    "masks, boxes, scores = output[\"masks\"], output[\"boxes\"], output[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8e93051-6531-4d8a-b080-b944da1bb356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           ...,\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False]]]], device='cuda:0'),\n",
       " tensor([[  85.4299,  281.5704, 1710.3721,  850.5768]], device='cuda:0'),\n",
       " tensor([0.8647], device='cuda:0'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks, boxes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28bb88cd-6af3-4951-be34-3d7da4c56305",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 1800), |u1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/surgical-instrument-count/.venv/lib/python3.12/site-packages/PIL/Image.py:3304\u001b[39m, in \u001b[36mfromarray\u001b[39m\u001b[34m(obj, mode)\u001b[39m\n\u001b[32m   3303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3304\u001b[39m     typemode, rawmode, color_modes = \u001b[43m_fromarray_typemap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtypekey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   3305\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyError\u001b[39m: ((1, 1, 1800), '|u1')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43moverlay_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36moverlay_masks\u001b[39m\u001b[34m(image, masks)\u001b[39m\n\u001b[32m      7\u001b[39m colors = [\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mint\u001b[39m(c * \u001b[32m255\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cmap(i)[:\u001b[32m3\u001b[39m])\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_masks)\n\u001b[32m     10\u001b[39m ]\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mask, color \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(masks, colors):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     mask = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     overlay = Image.new(\u001b[33m\"\u001b[39m\u001b[33mRGBA\u001b[39m\u001b[33m\"\u001b[39m, image.size, color + (\u001b[32m0\u001b[39m,))\n\u001b[32m     15\u001b[39m     alpha = mask.point(\u001b[38;5;28;01mlambda\u001b[39;00m v: \u001b[38;5;28mint\u001b[39m(v * \u001b[32m0.5\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/surgical-instrument-count/.venv/lib/python3.12/site-packages/PIL/Image.py:3308\u001b[39m, in \u001b[36mfromarray\u001b[39m\u001b[34m(obj, mode)\u001b[39m\n\u001b[32m   3306\u001b[39m         typekey_shape, typestr = typekey\n\u001b[32m   3307\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot handle this data type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypekey_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypestr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m3308\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   3309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode != typemode \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m color_modes:\n",
      "\u001b[31mTypeError\u001b[39m: Cannot handle this data type: (1, 1, 1800), |u1"
     ]
    }
   ],
   "source": [
    "overlay_masks(image, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28276ba6-c811-49f1-806a-67364f632d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
